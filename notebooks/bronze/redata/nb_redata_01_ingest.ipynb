{"cells":[{"cell_type":"code","source":["import requests, json, time, logging, unicodedata, re\n","from datetime import datetime, timedelta\n","from pyspark.sql import SparkSession\n","from typing import Dict, Optional\n","from notebookutils import mssparkutils"],"outputs":[],"execution_count":null,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"a53e4c22-e413-4b6c-a00f-39723baf7304"},{"cell_type":"code","source":["start_date_param = \"\"\n","end_date_param = \"\"\n","max_combinations_param = \"\"\n","lakehouse_path_param = \"Files/bronze/REDATA\"\n","\n","# Obtener par√°metros del pipeline\n","if 'start_date' in locals() or 'start_date' in globals():\n","    start_date_param = start_date if 'start_date' in locals() else globals().get('start_date', \"\")\n","if 'end_date' in locals() or 'end_date' in globals():\n","    end_date_param = end_date if 'end_date' in locals() else globals().get('end_date', \"\")\n","if 'max_combinations' in locals() or 'max_combinations' in globals():\n","    max_combinations_param = max_combinations if 'max_combinations' in locals() else globals().get('max_combinations', \"\")\n","if 'lakehouse_path' in locals() or 'lakehouse_path' in globals():\n","    lakehouse_path_param = lakehouse_path if 'lakehouse_path' in locals() else globals().get('lakehouse_path', \"Files/bronze/REDATA\")\n","\n","print(f\"Par√°metros recibidos:\")\n","print(f\"  start_date: '{start_date_param}'\")\n","print(f\"  end_date: '{end_date_param}'\")\n","print(f\"  max_combinations: '{max_combinations_param}'\")\n","print(f\"  lakehouse_path: '{lakehouse_path_param}'\")"],"outputs":[],"execution_count":null,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"ddf991ed-7963-4c03-8cb0-52f9af9439d5"},{"cell_type":"code","source":["# ============================================\n","# Configuraci√≥n y load_config\n","# ============================================\n","\n","logging.basicConfig(level=logging.INFO)\n","logger = logging.getLogger(__name__)\n","spark = SparkSession.builder.appName(\"REData_API_Explorer\").getOrCreate()\n","\n","\n","def load_config():\n","    \"\"\"Carga configuraci√≥n externa\"\"\"\n","    config_path = \"Files/config/redata_config.json\"\n","    try:\n","        content = mssparkutils.fs.head(config_path, 100000)\n","        config_data = json.loads(content)\n","        print(\"‚úÖ Configuraci√≥n cargada desde redata_config.json\")\n","        return config_data\n","    except Exception as e:\n","        logger.warning(f\"‚ö†Ô∏è No se pudo cargar config: {e}\")\n","        logger.warning(\"Usando valores por defecto\")\n","        return {\n","            \"ccaa_ids\": {\n","                \"Pen√≠nsula\": 8741,\n","                \"Islas Canarias\": 8742,\n","                \"Islas Baleares\": 8743,\n","                \"Ceuta\": 8744,\n","                \"Melilla\": 8745,\n","                \"Andaluc√≠a\": 4,\n","                \"Arag√≥n\": 5,\n","                \"Cantabria\": 6,\n","                \"Castilla-La Mancha\": 7,\n","                \"Castilla y Le√≥n\": 8,\n","                \"Catalu√±a\": 9,\n","                \"Pa√≠s Vasco\": 10,\n","                \"Principado de Asturias\": 11,\n","                \"Comunidad de Madrid\": 13,\n","                \"Comunidad de Navarra\": 14,\n","                \"Comunidad Valenciana\": 15,\n","                \"Extremadura\": 16,\n","                \"Galicia\": 17,\n","                \"La Rioja\": 20,\n","                \"Regi√≥n de Murcia\": 21\n","            },\n","            \"api_config\": {\n","                \"balance\": [\"balance-electrico\"],\n","                \"demanda\": [\"evolucion\"],\n","                \"generacion\": [\n","                    \"estructura-generacion\",\n","                    \"estructura-generacion-emisiones-asociadas\",\n","                    \"estructura-renovables\",\n","                    \"evolucion-renovable-no-renovable\"\n","                ]\n","            }\n","        }"],"outputs":[],"execution_count":null,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"d6d9bed8-09e0-4e48-ad3c-1f669a42c35b"},{"cell_type":"code","source":["# ============================================\n","# Clase REDataAPIExplorer\n","# ============================================\n","\n","class REDataAPIExplorer:\n","    def __init__(self, base_lakehouse_path: str, start_date: str = None, end_date: str = None):\n","        self.base_url = \"https://apidatos.ree.es\"\n","        self.base_lakehouse_path = base_lakehouse_path\n","        self.session = requests.Session()\n","        self.headers = {\"Accept\": \"application/json\", \"Content-Type\": \"application/json\"}\n","        \n","        # Cargar configuraci√≥n\n","        config = load_config()\n","        self.ccaa_ids = config[\"ccaa_ids\"]\n","        self.api_config = config[\"api_config\"]\n","        \n","        # Fechas\n","        if start_date and end_date:\n","            self.start_date = datetime.fromisoformat(start_date.replace('Z', '+00:00'))\n","            self.end_date = datetime.fromisoformat(end_date.replace('Z', '+00:00'))\n","        else:\n","            self.end_date = datetime.now()\n","            self.start_date = self.end_date - timedelta(days=365)\n","        \n","        self.logs_success = f\"{self.base_lakehouse_path}/logs/success.log\"\n","        self.logs_error = f\"{self.base_lakehouse_path}/logs/error.log\"\n","    \n","    def _slugify(self, text: str) -> str:\n","        \"\"\"Convierte texto a formato slug\"\"\"\n","        t = unicodedata.normalize(\"NFKD\", text).encode(\"ascii\", \"ignore\").decode(\"ascii\")\n","        return re.sub(r\"[^a-z0-9\\-]\", \"\", t.lower().replace(\" \", \"-\"))\n","    \n","    def _clean_timestamp(self, timestamp: str) -> str:\n","        \"\"\"Limpia timestamp para nombre de archivo\"\"\"\n","        return timestamp.lower().replace(\":\", \"-\").replace(\".\", \"-\")\n","    \n","    def build_api_url(self, lang, category, widget, time_trunc, geo_id, geo_name):\n","        \"\"\"Construye URL de API - SIEMPRE usando geo_limit=ccaa\"\"\"\n","        start_str = self.start_date.strftime(\"%Y-%m-%dT%H:%M\")\n","        end_str = self.end_date.strftime(\"%Y-%m-%dT%H:%M\")\n","        base = f\"{self.base_url}/{lang}/datos/{category}/{widget}\"\n","        \n","        params = {\n","            \"start_date\": start_str,\n","            \"end_date\": end_str,\n","            \"time_trunc\": time_trunc,\n","            \"geo_trunc\": \"electric_system\",\n","            \"geo_limit\": \"ccaa\",\n","            \"geo_ids\": str(geo_id)\n","        }\n","        \n","        query = \"&\".join([f\"{k}={v}\" for k, v in params.items()])\n","        return f\"{base}?{query}\"\n","    \n","    def make_api_request(self, url: str):\n","        \"\"\"Realiza petici√≥n a la API\"\"\"\n","        try:\n","            r = self.session.get(url, headers=self.headers, timeout=20)\n","            if r.status_code == 200:\n","                return True, r.json()\n","            return False, {}\n","        except Exception:\n","            return False, {}\n","    \n","    def save_to_bronze(self, data, category, widget, region, timestamp, time_trunc, \n","                       geo_id, geo_name):\n","        \"\"\"Guarda datos en bronze con metadata\"\"\"\n","        enriched_data = {\n","            \"request_metadata\": {\n","                \"geo_id\": geo_id,\n","                \"geo_name\": geo_name,\n","                \"geo_limit\": \"ccaa\",\n","                \"category\": category,\n","                \"widget\": widget,\n","                \"time_trunc\": time_trunc,\n","                \"ingestion_timestamp\": timestamp,\n","                \"start_date\": self.start_date.isoformat(),\n","                \"end_date\": self.end_date.isoformat()\n","            },\n","            \"api_response\": data\n","        }\n","        \n","        clean_ts = self._clean_timestamp(timestamp)\n","        fname = f\"brz-{region}-{category}-{widget}-{time_trunc}-{clean_ts}.json\"\n","        path = f\"{self.base_lakehouse_path}/data/{category}/{widget}/{time_trunc}/{fname}\"\n","        mssparkutils.fs.put(path, json.dumps(enriched_data, indent=2, ensure_ascii=False), overwrite=True)\n","        logger.info(f\"‚úÖ Guardado: {path}\")\n","    \n","    def log(self, path, msg: str):\n","        \"\"\"Guarda log\"\"\"\n","        try:\n","            mssparkutils.fs.put(path, msg + \"\\n\", overwrite=False)\n","        except:\n","            try:\n","                old = mssparkutils.fs.head(path, 1000000)\n","            except:\n","                old = \"\"\n","            mssparkutils.fs.put(path, old + msg + \"\\n\", overwrite=True)\n","    \n","    def explore_single(self, lang, category, widget, time_trunc, geo_id, geo_name):\n","        \"\"\"Explora un endpoint espec√≠fico\"\"\"\n","        ts = datetime.utcnow().isoformat(timespec=\"microseconds\") + \"Z\"\n","        url = self.build_api_url(lang, category, widget, time_trunc, geo_id, geo_name)\n","        success, data = self.make_api_request(url)\n","        has_data = success and bool(data.get(\"included\"))\n","        \n","        region = self._slugify(geo_name)\n","        \n","        if has_data:\n","            self.save_to_bronze(data, category, widget, region, ts, time_trunc, geo_id, geo_name)\n","            self.log(self.logs_success, f\"{ts} OK {url}\")\n","        else:\n","            self.log(self.logs_error, f\"{ts} FAIL {url}\")\n","        \n","        return {\"url\": url, \"success\": success, \"has_data\": has_data}\n","    \n","    def explore_all(self, max_combinations=None):\n","        \"\"\"\n","        Explora API - SOLO DATOS MENSUALES Y SOLO geo_limit=ccaa\n","        \"\"\"\n","        combos = []\n","        \n","        for cat, widgets in self.api_config.items():\n","            for widget in widgets:\n","                # ‚úÖ SOLO MENSUALES + SOLO CCAA\n","                for geo_name, geo_id in self.ccaa_ids.items():\n","                    combos.append((\"es\", cat, widget, \"month\", geo_id, geo_name))\n","        \n","        if max_combinations:\n","            combos = combos[:max_combinations]\n","        \n","        logger.info(f\"üöÄ Ejecutando {len(combos)} combinaciones (SOLO MENSUALES + CCAA)\")\n","        results = []\n","        for c in combos:\n","            results.append(self.explore_single(*c))\n","            time.sleep(0.2)\n","        return results\n","    \n","    def analyze_results(self, results):\n","        \"\"\"Analiza resultados\"\"\"\n","        total = len(results)\n","        ok = sum(r[\"success\"] for r in results)\n","        with_data = sum(r[\"has_data\"] for r in results)\n","        return {\"total\": total, \"ok\": ok, \"with_data\": with_data, \"failures\": total - ok}\n"],"outputs":[],"execution_count":null,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"d7a457dd-09fe-4874-994d-bbd7a7605225"},{"cell_type":"code","source":["def main():\n","    max_comb = int(max_combinations_param.strip()) if max_combinations_param and max_combinations_param.strip().isdigit() else None\n","    \n","    explorer = REDataAPIExplorer(\n","        base_lakehouse_path=lakehouse_path_param,\n","        start_date=start_date_param if start_date_param else None,\n","        end_date=end_date_param if end_date_param else None\n","    )\n","    \n","    print(f\"üöÄ Iniciando ingesta REData\")\n","    print(f\"üìÖ Rango: {explorer.start_date} - {explorer.end_date}\")\n","    print(f\"üî¢ Max combinaciones: {max_comb or 'Todas'}\")\n","    print(f\"‚úÖ SOLO MENSUALES + geo_limit=ccaa\")\n","    print(f\"‚ùå Endpoints excluidos: generacion/maxima-renovable, mercados/componentes-precio\")\n","    \n","    results = explorer.explore_all(max_combinations=max_comb)\n","    summary = explorer.analyze_results(results)\n","    print(\"üìä Resumen:\", summary)\n","    return summary\n","\n","if __name__ == \"__main__\":\n","    main()"],"outputs":[],"execution_count":null,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"8ea4e7dd-97a6-45d5-ad62-ccacbc817a5e"}],"metadata":{"kernel_info":{"name":"synapse_pyspark"},"kernelspec":{"name":"synapse_pyspark","display_name":"synapse_pyspark"},"language_info":{"name":"python"},"microsoft":{"language":"python","language_group":"synapse_pyspark","ms_spell_check":{"ms_spell_check_language":"en"}},"nteract":{"version":"nteract-front-end@1.0.0"},"spark_compute":{"compute_id":"/trident/default","session_options":{"conf":{"spark.synapse.nbs.session.timeout":"1200000"}}},"dependencies":{"lakehouse":{"known_lakehouses":[{"id":"0fd09a67-0164-4fb6-838e-02a27c823afc"}],"default_lakehouse":"0fd09a67-0164-4fb6-838e-02a27c823afc","default_lakehouse_name":"lh_bronze","default_lakehouse_workspace_id":"ecf938c4-c449-48de-a07c-1d968a72b3d1"}}},"nbformat":4,"nbformat_minor":5}