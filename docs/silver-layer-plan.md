# Silver Layer Implementation Plan - OMIE Energy Data

## ğŸ“ Recommended Directory Structure

```
notebooks/
â”œâ”€â”€ bronze/
â”‚   â””â”€â”€ OMIE/
â”‚       â”œâ”€â”€ 2023/
â”‚       â”œâ”€â”€ 2024/
â”‚       â””â”€â”€ 2025/
â”œâ”€â”€ silver/
â”‚   â””â”€â”€ OMIE/
â”‚       â”œâ”€â”€ cleaned/
â”‚       â”œâ”€â”€ enriched/
â”‚       â””â”€â”€ integrated/
â””â”€â”€ gold/
    â””â”€â”€ OMIE/
        â”œâ”€â”€ aggregated/
        â””â”€â”€ kpis/
```

## ğŸ¥ˆ Silver Layer Transformations

### 1. Data Cleaning & Quality (Priority 1)

- **Remove duplicates** based on timestamp + file source
- **Handle null values** (imputation or removal strategies)
- **Detect and flag anomalies** (negative prices, impossible demand values)
- **Standardize timestamps** to UTC with proper timezone handling
- **Validate data ranges** (reasonable bounds for demand, prices)

### 2. Data Enrichment (Priority 1)

- **Technology Classification**:
  - Renewable vs Non-renewable
  - Conventional vs Storage
  - Carbon intensity categories
- **Temporal Features**:
  - Hour, day of week, month, season
  - Business day vs weekend/holiday flags
  - Peak/Off-peak hour classification
- **Calculated Metrics**:
  - CO2 emissions per MWh (using emission factors)
  - Renewable penetration percentage
  - Price volatility indicators
  - Demand vs generation gap

### 3. Data Integration (Priority 2)

- **Merge multiple OMIE data sources** (prices + demand + generation)
- **Add external context** (weather data, economic indicators if available)
- **Create unified energy model** with consistent schemas
- **Implement data lineage tracking**

### 4. Business Rules & Validation (Priority 2)

- **Energy balance validation** (generation = demand + losses + exports)
- **Price coherence checks** (prices within reasonable market bounds)
- **Seasonal pattern validation** (demand patterns match historical norms)
- **Data freshness monitoring** (identify stale or missing data)

## ğŸ› ï¸ Technical Implementation

### Option A: Fabric Pipeline (Recommended)

1. **Create Fabric Pipeline** with data flow activities
2. **Use Fabric Notebooks** for transformation logic
3. **Implement Delta Lake tables** for Silver layer storage
4. **Schedule pipeline runs** for incremental updates

### Option B: Databricks Pipeline (Advanced)

1. **Create Delta Live Tables (DLT)** pipeline
2. **Implement medallion architecture** with streaming
3. **Use Auto Loader** for incremental processing
4. **Apply data quality constraints**

### Option C: Python ETL Scripts (Simple)

1. **Create transformation notebooks** in current structure
2. **Use pandas/PySpark** for data processing
3. **Implement manual orchestration**
4. **Schedule via cron/Task Scheduler**

## ğŸ“Š Expected Outputs

### Silver Layer Tables

- `silver_omie_hourly_prices_cleaned`
- `silver_omie_demand_enriched`
- `silver_omie_generation_by_tech`
- `silver_omie_energy_balance`
- `silver_omie_emissions_calculated`
- `silver_omie_market_indicators`

### Quality Metrics

- Data completeness percentage
- Anomaly detection reports
- Data lineage documentation
- Transformation success rates

## ğŸ¯ Success Criteria

### Technical Success

- âœ… All Bronze data successfully transformed
- âœ… Data quality rules implemented and monitored
- âœ… No data loss during transformations
- âœ… Performance within acceptable limits
- âœ… Automated pipeline execution

### Business Success

- âœ… Data ready for Power BI consumption
- âœ… Analysts can trust data quality
- âœ… Anomalies (like 2025 blackout) properly identified
- âœ… Energy insights can be derived
- âœ… Regulatory compliance maintained

## ğŸš€ Next Phase: Gold Layer Preparation

- Aggregated tables for dashboard consumption
- KPI calculations (renewable percentage, emissions)
- Time-series models for Power BI
- Real-time data refresh capabilities
